{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShobitKapila/Acoustic-source-identification/blob/main/wind_turbin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature extraction for sound data often involves using signal processing libraries like librosa, extracting features such as Mel-frequency cepstral coefficients (MFCCs), spectral features, or others."
      ],
      "metadata": {
        "id": "QbSIHSCcDZ0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For finding the best threshold value for wind turbin generator - Plotting the precision-recall curve can help visualize the trade-off between precision and recall at different thresholds."
      ],
      "metadata": {
        "id": "Av9BLnAbQC0C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euBtE77r9JjS",
        "outputId": "d792b683-6cb5-4369-f892-b1261023bedb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Healthy Dataset:\n",
            "MATLAB file version: 1.0\n",
            "MATLAB file version: 1.0\n",
            "MATLAB file version: 1.0\n",
            "MATLAB file version: 1.0\n",
            "MATLAB file version: 1.0\n",
            "MATLAB file version: 1.0\n",
            "MATLAB file version: 1.0\n",
            "MATLAB file version: 1.0\n",
            "MATLAB file version: 1.0\n",
            "MATLAB file version: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from scipy.io import loadmat\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "\n",
        "# data pre-processing in batch size to resolve the memory allocation error\n",
        "def load_data(folder_path, batch_size=10):\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith(\".mat\"):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            try:\n",
        "                mat_data = loadmat(file_path)\n",
        "                mat_version = mat_data['__version__']\n",
        "                print(f'MATLAB file version: {mat_version}')\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading file {file_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "            for key in mat_data.keys():\n",
        "                if key.startswith('AN'):\n",
        "                    sample_data = mat_data[key]\n",
        "                    num_samples = sample_data.shape[0]\n",
        "\n",
        "                    num_batches = (num_samples + batch_size - 1) // batch_size\n",
        "\n",
        "                    for i in range(0, num_batches):\n",
        "                        start_idx = i * batch_size\n",
        "                        end_idx = min((i + 1) * batch_size, num_samples)\n",
        "                        yield sample_data[start_idx:end_idx], mat_data['Speed'][start_idx:end_idx]\n",
        "\n",
        "# feature extraction\n",
        "def extract_features_from_sound(sound_file_path):\n",
        "    y, sr = librosa.load(sound_file_path)\n",
        "    features = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    return features.T\n",
        "\n",
        "# training the dataset with test set\n",
        "def train_and_evaluate(X, y, save_model_path):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    clf = KNeighborsClassifier()\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "\n",
        "    plt.plot(thresholds, precision[:-1], label='Precision')\n",
        "    plt.plot(thresholds, recall[:-1], label='Recall')\n",
        "    plt.xlabel('Threshold')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    desired_precision = 0.8\n",
        "    desired_recall = 0.8\n",
        "\n",
        "    closest_precision_idx = np.argmax(precision >= desired_precision)\n",
        "    closest_recall_idx = np.argmax(recall >= desired_recall)\n",
        "\n",
        "    best_threshold = (thresholds[closest_precision_idx] + thresholds[closest_recall_idx]) / 2\n",
        "    print(f\"Best Threshold: {best_threshold}\")\n",
        "\n",
        "    y_pred = (y_pred_proba > best_threshold).astype(int)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    f1_acc = f1_score(y_test, y_pred)\n",
        "    print(f\"F1 Accuracy Score: {f1_acc}\")\n",
        "\n",
        "    joblib.dump(clf, save_model_path)\n",
        "    print(f\"Model saved to {save_model_path}\")\n",
        "\n",
        "# data processing and training\n",
        "def process_data_and_train(folder_path, save_model_path):\n",
        "    data_generator = load_data(folder_path)\n",
        "    X_chunks, y_chunks = zip(*data_generator)\n",
        "\n",
        "    X = np.concatenate(X_chunks, axis=0)\n",
        "    y = np.concatenate(y_chunks, axis=0)\n",
        "\n",
        "    train_and_evaluate(X, y, save_model_path)\n",
        "\n",
        "healthy_folder_path = \"C:/Users/Shobit/PycharmProjects/ASI_detection/Healthy\"\n",
        "damaged_folder_path = \"C:/Users/Shobit/PycharmProjects/ASI_detection/Damaged\"\n",
        "\n",
        "healthy_model_path = \"D:/wind turbin/healthy_model.joblib\"\n",
        "damaged_model_path = \"D:/wind turbin/damaged_model.joblib\"\n",
        "\n",
        "print(\"Healthy Dataset:\")\n",
        "process_data_and_train(healthy_folder_path, healthy_model_path)\n",
        "\n",
        "print(\"\\nDamaged Dataset:\")\n",
        "process_data_and_train(damaged_folder_path, damaged_model_path)\n",
        "\n",
        "# driver code\n",
        "sound_file_path = \"C:/Users/Shobit/PycharmProjects/ASI_detection/Healthy_turbin.mp3\"\n",
        "sound_features = extract_features_from_sound(sound_file_path)\n",
        "model = joblib.load(healthy_model_path)\n",
        "prediction = model.predict(sound_features.reshape(1, -1))\n",
        "print(f\"The predicted healthiness is: {'Damaged' if prediction == 1 else 'Healthy'}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGGJ7+Pqc4AAkNeAvjCL1g",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}